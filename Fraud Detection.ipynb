{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhrBOtrKEtF1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"bs140513_032310.csv\")\n",
        "\n",
        "# Removing unneeded features\n",
        "remove_columns = ['zipcodeOri', 'zipMerchant']\n",
        "df = df.drop(columns=remove_columns)\n",
        "\n",
        "# Feature engineering: Creating new features\n",
        "df['transaction_amount_per_merchant'] = df.groupby('merchant')['amount'].transform('mean')\n",
        "df['transaction_frequency'] = df.groupby('customer')['step'].transform('count')\n",
        "\n",
        "# Label encoding categorical data\n",
        "for column in ['customer', 'age', 'gender', 'merchant', 'category']:\n",
        "    df[column] = LabelEncoder().fit_transform(df[column])\n",
        "\n",
        "# Splitting data into features and target\n",
        "X = df.drop('fraud', axis=1)\n",
        "y = df['fraud']\n",
        "\n",
        "# Displaying the class distribution\n",
        "class_df = pd.DataFrame(df['fraud'].value_counts().rename_axis('fraud').reset_index(name='number'))\n",
        "class_df['fraud'].replace({0: 'Normal', 1: 'Fraud'}, inplace=True)\n",
        "fig = plt.figure()\n",
        "ax = sns.barplot(x=class_df['fraud'], y=class_df['number'])\n",
        "ax.bar_label(ax.containers[0], color='black')\n",
        "plt.title(label='Normal vs Fraud')\n",
        "\n",
        "# Splitting the data into training, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Applying SMOTE to the imbalanced data\n",
        "smote = SMOTE(random_state=42)\n",
        "X_res, y_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Hyperparameter tuning for each base model\n",
        "\n",
        "# 1. RandomForestClassifier\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [10, 20, None],\n",
        "    'min_samples_split': [2, 5],\n",
        "}\n",
        "grid_search_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=3, scoring='f1')\n",
        "grid_search_rf.fit(X_res, y_res)\n",
        "best_rf_model = grid_search_rf.best_estimator_\n",
        "\n",
        "# 2. XGBClassifier\n",
        "param_grid_xgb = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 6, 10],\n",
        "}\n",
        "grid_search_xgb = GridSearchCV(XGBClassifier(random_state=42), param_grid_xgb, cv=3, scoring='f1')\n",
        "grid_search_xgb.fit(X_res, y_res)\n",
        "best_xgb_model = grid_search_xgb.best_estimator_\n",
        "\n",
        "# 3. LogisticRegression\n",
        "param_grid_lr = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'solver': ['liblinear', 'lbfgs']\n",
        "}\n",
        "grid_search_lr = GridSearchCV(LogisticRegression(max_iter=1000, random_state=42), param_grid_lr, cv=3, scoring='f1')\n",
        "grid_search_lr.fit(X_res, y_res)\n",
        "best_lr_model = grid_search_lr.best_estimator_\n",
        "\n",
        "# 4. KNeighborsClassifier\n",
        "param_grid_knn = {\n",
        "    'n_neighbors': [3, 5, 7],\n",
        "    'weights': ['uniform', 'distance']\n",
        "}\n",
        "grid_search_knn = GridSearchCV(KNeighborsClassifier(), param_grid_knn, cv=3, scoring='f1')\n",
        "grid_search_knn.fit(X_res, y_res)\n",
        "best_knn_model = grid_search_knn.best_estimator_\n",
        "\n",
        "# 5. DecisionTreeClassifier\n",
        "param_grid_dt = {\n",
        "    'max_depth': [10, 20, None],\n",
        "    'min_samples_split': [2, 5],\n",
        "}\n",
        "grid_search_dt = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid_dt, cv=3, scoring='f1')\n",
        "grid_search_dt.fit(X_res, y_res)\n",
        "best_dt_model = grid_search_dt.best_estimator_\n",
        "\n",
        "# GaussianNB does not have hyperparameters to tune\n",
        "\n",
        "# List of the tuned base models\n",
        "base_models = [\n",
        "    ('rf', best_rf_model),\n",
        "    ('xgb', best_xgb_model),\n",
        "    ('nb', GaussianNB()),\n",
        "    ('lr', best_lr_model),\n",
        "    ('knn', best_knn_model),\n",
        "    ('dt', best_dt_model),\n",
        "]\n",
        "\n",
        "# Creating the VotingClassifier with majority voting\n",
        "ensemble_classifier = VotingClassifier(estimators=base_models, voting='hard')\n",
        "\n",
        "# Fitting the ensemble classifier on SMOTE-resampled training data\n",
        "ensemble_classifier.fit(X_res, y_res)\n",
        "\n",
        "# Predicting using the ensemble model on the validation set\n",
        "y_pred_val_ensemble = ensemble_classifier.predict(X_val)\n",
        "\n",
        "# Evaluating the ensemble model's performance on validation data\n",
        "accuracy_val_ensemble = accuracy_score(y_val, y_pred_val_ensemble)\n",
        "f1_val_ensemble = f1_score(y_val, y_pred_val_ensemble)\n",
        "precision_val_ensemble = precision_score(y_val, y_pred_val_ensemble)\n",
        "recall_val_ensemble = recall_score(y_val, y_pred_val_ensemble)\n",
        "\n",
        "print(\"\\nEnsemble Model Performance on Validation Data:\")\n",
        "print(\"Accuracy:\", accuracy_val_ensemble)\n",
        "print(\"F1-score:\", f1_val_ensemble)\n",
        "print(\"Precision:\", precision_val_ensemble)\n",
        "print(\"Recall:\", recall_val_ensemble)\n",
        "conf_matrix_val_ensemble = confusion_matrix(y_val, y_pred_val_ensemble)\n",
        "sns.heatmap(conf_matrix_val_ensemble, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix (Validation Data)')\n",
        "plt.show()\n",
        "\n",
        "# Predicting using the ensemble model on testing data\n",
        "y_pred_test_ensemble = ensemble_classifier.predict(X_test)\n",
        "\n",
        "# Evaluating the ensemble model's performance on testing data\n",
        "accuracy_test_ensemble = accuracy_score(y_test, y_pred_test_ensemble)\n",
        "f1_test_ensemble = f1_score(y_test, y_pred_test_ensemble)\n",
        "precision_test_ensemble = precision_score(y_test, y_pred_test_ensemble)\n",
        "recall_test_ensemble = recall_score(y_test, y_pred_test_ensemble)\n",
        "\n",
        "print(\"\\nEnsemble Model Performance on Testing Data:\")\n",
        "print(\"Accuracy:\", accuracy_test_ensemble)\n",
        "print(\"F1-score:\", f1_test_ensemble)\n",
        "print(\"Precision:\", precision_test_ensemble)\n",
        "print(\"Recall:\", recall_test_ensemble)\n",
        "conf_matrix_test_ensemble = confusion_matrix(y_test, y_pred_test_ensemble)\n",
        "sns.heatmap(conf_matrix_test_ensemble, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix (Testing Data)')\n",
        "plt.show()\n"
      ]
    }
  ]
}